<div style="width: 50em;">

<p>
Herzlich Willkommen! 
</p>
<p>
In unserer aktuellen Studie wollen wir herausfinden, wie Muttersprachler*innen audiovisuell pr&auml;sentierte Sprachsignale verarbeiten. Zu diesem Zwecke werden wir Ihnen deutsche S&auml;tze &uuml;ber Kopfh&ouml;rer vorspielen, w&auml;hrend Sie die Lippen der sprechenden Person auf einem Computerbildschirm betrachten. F&uuml;r die Studie werden wir Daten mit den folgenden Methoden erfassen</p>

<p>
<b>Fragebogen:</b> Wir werden Sie vor Beginn der Hauptuntersuchung bitten, eine Reihe von Fragen zu beantworten.</p>

<p>
<b>Synchronit&auml;tsbewertung:</b> Wir werden Sie bitten zu beurteilen, ob Sie das Video der sprechenden Person als synchron zum auditorischen Signal (der Stimme) wahrnehmen.</p>

<p>
<b>Wortidentifikation:</b> W&auml;hrend Sie den Satz anh&ouml;ren, werden Sie zwei Bilder auf dem Bildschirm sehen. Ihre Aufgabe wird sein, m&ouml;glichst schnell dasjenige Bild auszuw&auml;hlen, das als Wort in dem geh&ouml;rten Satz erw&auml;hnt wird.</p>

<p>
W&auml;hrend des Experiments erhalten Sie ausreichend Zeit f&uuml;r kurze Pausen, in denen Sie etwas trinken k&ouml;nnen und
sich kurz entspannen d&uuml;rfen. Das Experiment dauert insgesamt ca. 45 Minuten.</p>

<p>
Die Untersuchung wird mit 1 VP-Stunde verg&uuml;tet. Sie k&ouml;nnen die Untersuchung jederzeit abbrechen ohne negative Konsequenzen erwarten zu m&uuml;ssen. Ihre Daten werden in diesem Fall automatisch gel&ouml;scht. </p>

<p>
Die Datenaufzeichnung wird so pseudonymisiert (d.h. nur mit einer bedeutungslosen Probandennummer abgelegt), dass aus den erhobenen Daten R&uuml;ckschl&uuml;sse auf Ihre Person ausgeschlossen sind. Auschlie&szlig;lich am Projekt beteiligte Wissenschaftler*innen (siehe unten) k&ouml;nnen die erfassten Daten mit Ihren pers&ouml;nlichen Daten in Verbindung bringen. Der Zugang zu den Daten wird nur den am Projekt beteiligten Wissenschaftler*innen gew&auml;hrt. Studienergebnisse k&ouml;nnen in anonymisierter Form ver&ouml;ffentlicht werden, die Ver&ouml;ffentlichung kann in wissenschaftlichen Publikationen oder auf Kongressen erfolgen.</p>

<p>
Falls Sie Fragen haben, z&ouml;gern Sie bitte nicht, sich bei uns zu melden! Wenn Sie zur Teilnahme bereit sind, bitten wir Sie, die auf der nächsten Seite folgende Einverst&auml;ndniserkl&auml;rung gr&uuml;ndlich zu lesen und zu best&auml;tigen.</p>
<p>
Mit freundlichen Gr&uuml;&szlig;en<br>
Aron Petau</p>

<p>
<b>Leitung des Projekts:</b><br>
Prof. Dr. Jérémie Voix<sup>1</sup></p>
<p>
<b>Beteiligte Mitarbeiterinnen:</b><br>
Danielle Benesch<sup>1</sup><br>
Juliane Schwab<sup>2,3</sup><br></p>
<b>Beteiligte Institutionen/Geldgeber:</b><br>
<sup>1</sup>NSERC-EERS Industrial Research Chair in In-Ear Technologies (CRITIAS), Université de Québec (ÉTS)<br>
<sup>2</sup>Universit&auml;t Osnabr&uuml;ck (Institut f&uuml;r Kognitionswi&szlig;enschaft)<br>
<sup>3</sup>Graduiertenkolleg Computational Cognition (DFG-GRK 2340)<br><br>