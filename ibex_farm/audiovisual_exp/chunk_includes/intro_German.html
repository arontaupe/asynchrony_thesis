<div style="width: 50em;">

<p>
Herzlich Willkommen!
</p>
<p>
In unserer aktuellen Studie wollen wir herausfinden, wie Muttersprachler*innen audiovisuell pr&auml;sentierte Sprachsignale verarbeiten.
Zu diesem Zwecke werden wir Ihnen deutsche S&auml;tze &uuml;ber Kopfh&ouml;rer vorspielen,
w&auml;hrend Sie die Lippen der sprechenden Person auf einem Computerbildschirm betrachten.
F&uuml;r die Studie werden wir Daten mit den folgenden Methoden erfassen:</p>

<p>
<b>Fragebogen:</b> Wir werden Sie vor Beginn der Hauptuntersuchung bitten, eine Reihe von Fragen zu beantworten.</p>

<p>
<b>Synchronit&auml;tsbewertung:</b> Wir werden Sie bitten zu beurteilen, ob Sie das Video der sprechenden Person als synchron zum auditorischen Signal (der Stimme) wahrnehmen.</p>

<p>
<b>Distortionsbewertung:</b> Wir werden Sie bitten zu beurteilen, ob Sie im auditorischen Signal (in der Stimme des Sprechers) Distortionen (Verzerrungen) wie zum Beispiel doppelte Stimmen wahrnehmen.</p>

<p>
<b>Zielwortidentifikation:</b>  Wir werden Ihnen zun&#228;chst ein Adjektiv zeigen, dieses m&uuml;ssen Sie sich merken, um die Aufgabe korrekt zu l&ouml;sen.
Bevor und w&auml;hrend Sie den Satz anh&ouml;ren, werden Sie zwei Bilder auf dem Bildschirm sehen.
Ihre Aufgabe wird sein, <b>m&ouml;glichst schnell</b> dasjenige Bild auszuw&auml;hlen, das als Wort in dem geh&ouml;rten Satz in Verbindung mit dem vorher gezeigten Adjektiv erw&auml;hnt wird.
Wir messen dabei Ihre Antwortgeschwindigkeit und die Richtigkeit Ihrer Antwort.</p>

<p>
W&auml;hrend des Experiments erhalten Sie ausreichend Zeit f&uuml;r kurze Pausen, in denen Sie etwas trinken k&ouml;nnen und
sich kurz entspannen d&uuml;rfen. Das Experiment dauert insgesamt ca. 45 Minuten.</p>
<p>
<b>Teilnahmekriterien</b> f&#252;r das Experiment sind:
<ul>
  <li><b>Deutsch als Muttersprache</b>,<br> es handelt sich um deutsche S&auml;tze und wir m&#252;ssen Verst&auml;ndnisprobleme ausschlie&#223;en k&#246;nnen.</li>
  <br>
  <li><b>Zugang zu einem Laptop oder Computer</b>,<br> die Teilnahme von mobilen Ger&auml;ten ist nicht m&#246;glich.</li>
  <br>
  <li><b>Ausreichende Sicht</b>, <br>sollten Sie Kontaktlinsen- oder Brillentr&#228;ger sein, bitten wir Sie, diese w&#228;hrend des Experiments aufzusetzen.</li>
  <br>
  <li><b>Volles H&#246;rverm&#246;gen</b>, <br>wenn Sie H&#246;rger&#228;te tragen, k&#246;nnen Sie leider nicht an unserer Studie teilnehmen.</li>
  <br>
  <li><b>Zugang zu kabelgebundenen Kopfh&#246;rern.</b> <br>Andere Audio&#252;bertragungsweisen, zum Beispiel Lautsprecher oder Bluetoothkopfh&#246;rer, m&#252;ssen wir ausschlie&#223;en k&#246;nnen. </li>
</ul>
</p>

<p>
  Das Experiment belegt einen gro&#223;en Anteil Arbeitsspeicher, da dort zur verz&#246;gerungsfreien Wiedergabe alle Videos vorweg geladen werden. Um technische Probleme zu vermeiden,
  schlie&#223;en Sie bitte alle anderen Programme und Tabs im Browser.
<p>
Die Untersuchung wird f&#252;r Studierende des Studienganges Cognitive Science mit 1 VP-Stunde verg&uuml;tet.
Studierende anderer Studieng&#228;nge k&#246;nnen diese leider von uns nicht erhalten, sind aber herzlich eingeladen, dennoch teilzunehmen.
Sie k&ouml;nnen die Untersuchung jederzeit abbrechen ohne negative Konsequenzen erwarten zu m&uuml;ssen. Ihre Daten werden in diesem Fall automatisch gel&ouml;scht. </p>

<p>
Die Datenaufzeichnung wird so pseudonymisiert (d.h. nur mit einer bedeutungslosen Probandennummer abgelegt), dass aus den erhobenen Daten R&uuml;ckschl&uuml;sse auf Ihre Person ausgeschlossen sind. Auschlie&szlig;lich am Projekt beteiligte Wissenschaftler*innen (siehe unten) k&ouml;nnen die erfassten Daten mit Ihren pers&ouml;nlichen Daten in Verbindung bringen. Der Zugang zu den Daten wird nur den am Projekt beteiligten Wissenschaftler*innen gew&auml;hrt. Studienergebnisse k&ouml;nnen in anonymisierter Form ver&ouml;ffentlicht werden, die Ver&ouml;ffentlichung kann in wissenschaftlichen Publikationen oder auf Kongressen erfolgen.</p>

<p>
Falls Sie Fragen haben, z&ouml;gern Sie bitte nicht, sich bei uns zu melden! Wenn Sie zur Teilnahme bereit sind, bitten wir Sie, die auf der n&#228;chsten Seite folgende Einverst&auml;ndniserkl&auml;rung gr&uuml;ndlich zu lesen und zu best&auml;tigen.</p>
<p>
Mit freundlichen Gr&uuml;&szlig;en,<br><br>
Aron Petau <br>
aron@petau.net</p>

<br>
<p>
<b>Leitung des Projekts:</b><br>
Prof. Dr. J&#233;r&#233;mie Voix<sup>1</sup></p>
<p>
<b>Beteiligte Mitarbeiterinnen:</b><br>
Danielle Benesch<sup>1</sup><br>
Juliane Schwab<sup>2,3</sup><br></p>
<b>Beteiligte Institutionen/Geldgeber:</b><br>
<sup>1</sup>NSERC-EERS Industrial Research Chair in In-Ear Technologies (CRITIAS), Universit&#233; de Qu&#233;bec (&#201;TS)<br>
<sup>2</sup>Universit&auml;t Osnabr&uuml;ck (Institut f&uuml;r Kognitionswissenschaft)<br>
<sup>3</sup>Graduiertenkolleg Computational Cognition (DFG-GRK 2340)<br><br>
