@article{GRANT200443,
title = {Detection of auditory (cross-spectral) and auditory–visual (cross-modal) synchrony},
journal = {Speech Communication},
volume = {44},
number = {1},
pages = {43-53},
year = {2004},
note = {Special Issue on Audio Visual speech processing},
issn = {0167-6393},
doi = {https://doi.org/10.1016/j.specom.2004.06.004},
url = {https://www.sciencedirect.com/science/article/pii/S0167639304001013},
author = {Ken W. Grant and Virginie van Wassenhove and David Poeppel},
keywords = {Spectro-temporal asynchrony, Cross-modal asynchrony, auditory–visual speech processing},
abstract = {Detection thresholds for temporal synchrony in auditory and auditory–visual sentence materials were obtained on normal-hearing subjects. For auditory conditions, thresholds were determined using an adaptive-tracking procedure to control the degree of temporal asynchrony of a narrow audio band of speech, both positive and negative in separate tracks, relative to three other narrow audio bands of speech. For auditory–visual conditions, thresholds were determined in a similar manner for each of four narrow audio bands of speech as well as a broadband speech condition, relative to a video image of a female speaker. Four different auditory filter conditions, as well as a broadband auditory–visual speech condition, were evaluated in order to determine whether detection thresholds were dependent on the spectral content of the acoustic speech signal. Consistent with previous studies of auditory–visual speech recognition which showed a broad, asymmetrical range of temporal synchrony for which intelligibility was basically unaffected (audio delays roughly between −40ms and +240ms), auditory–visual synchrony detection thresholds also showed a broad, asymmetrical pattern of similar magnitude (audio delays roughly between −45ms and +200ms). No differences in synchrony thresholds were observed for the different filtered bands of speech, or for broadband speech. In contrast, detection thresholds for audio-alone conditions were much smaller (between −17ms and +23ms) and symmetrical. These results suggest a fairly tight coupling between a subject’s ability to detect cross-spectral (auditory) and cross-modal (auditory–visual) asynchrony and the intelligibility of auditory and auditory–visual speech materials.}
}